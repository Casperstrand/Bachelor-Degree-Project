{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmetizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = [w for w in text if w.lower() not in stopwords]\n",
    "    return text\n",
    "\n",
    "def lemmetize_words(word_list):\n",
    "    lemmetized = [lemmetizer.lemmatize(w) for w in word_list]\n",
    "    return lemmetized\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = [w for w in text if w.isalnum()]\n",
    "    return text\n",
    "\n",
    "def remove_non_english_words(text):\n",
    "    printable = set(string.printable)\n",
    "    return [word for word in text \n",
    "            if all(char in printable for char in word)]\n",
    "\n",
    "def fix_text(row):\n",
    "    return ' '.join(row)\n",
    "\n",
    "df = pd.read_csv('amazon_cells_labelled.txt', sep=\"\\t\", header=None, engine='python')\n",
    "df = df.rename(columns={0: 'text', 1: 'label'})\n",
    "df = df.dropna()\n",
    "df['final_text'] = df['text'].apply(nltk.word_tokenize)\n",
    "df['final_text'] = df['final_text'].apply(remove_special_characters)\n",
    "df['final_text'] = df['final_text'].apply(remove_non_english_words)\n",
    "df['final_text'] = df['final_text'].apply(remove_stop_words)\n",
    "df['final_text'] = df['final_text'].apply(lemmetize_words)\n",
    "df['final_text'] = df['final_text'].apply(fix_text)\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df['final_text'], df['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidvect = TfidfVectorizer(max_features=5000)\n",
    "tfidvect.fit(df['final_text'])\n",
    "train_x_tfidf = tfidvect.transform(train_x)\n",
    "test_x_tfidf = tfidvect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_x_tfidf, train_y)\n",
    "pred = model.predict(test_x_tfidf)\n",
    "accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 518)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "api_key = \"PnlZWeBFRKSAPq30VXxZf2ndP\"\n",
    "api_secrets = \"Iv0RXWCfmI9kqHhsDDFX1DpKA6i35bY8S9lmstGbPXaGbNBbDo\"\n",
    "access_token = \"1932113076-5BikfTm3jjzd0WvT0JQIC8i1pPEVDAKVEko9Qb3\"\n",
    "access_secret = \"vgQYwJRtz2F65UsMSI0uZj4sRETZMCD182tBrB11MFWLG\"\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "search_query = \"#nike -filter:retweets\"\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=search_query, lang=\"en\").items(1000)\n",
    "\n",
    "tweets_copy = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy.append(tweet._json['text'])\n",
    "    \n",
    "def count(list):\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for line in list:\n",
    "        if model.predict(tfidvect.transform([line])) == 0:\n",
    "            negative_count += 1\n",
    "        elif model.predict(tfidvect.transform([line])) == 1:\n",
    "            positive_count += 1\n",
    "\n",
    "    return positive_count, negative_count\n",
    "\n",
    "count(tweets_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8930fd93c0d0e39a0d4d9dd43e222c1e36af1b68c0e251fae90799f6ab1738d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
